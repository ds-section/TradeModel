{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "def fetch_country(COMPANY_OID):\n",
    "    \"\"\"Return country of location of buyer's company.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def fetch_suppliers(code):\n",
    "    \"\"\"Return DataFrame of suppliers from TT selling product specified by code, indexed by `BAN_REAL`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    code : str\n",
    "        TAITRA code of len 4.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    suppliers : DataFrame\n",
    "        Columns: `n_items`, `product name`, and `product description`.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def fetch_export(supp_ban, ctry):\n",
    "    \"\"\"Return DataFrame of export records for all suppliers contained in `supp_ban`,\n",
    "    indexed by `BAN_REAL`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    supp_ban : list-like\n",
    "        `BAN_REAL` of target suppliers.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    export : DataFrame\n",
    "        Columns: `n_comm` (number of unique commodities exported by the supplier), `hs_desc`\n",
    "        (HS descriptions of commodities exported), and `isexporter` (boolean, whether the supplier\n",
    "        has shipped to buyer's country in the last five years).\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def compute_features(inq):\n",
    "    \"\"\"Return DataFrame of calculated features.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    inq : Series\n",
    "        Buyer inquiry.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : DataFrame\n",
    "        At present there are six features:\n",
    "        \n",
    "        1) name_match : how many words product name of inquiry and catalogue items share,\n",
    "              normalized by `n_items`\n",
    "              \n",
    "        2) desc_match : how many words product specification of inquiry and catalogue items share,\n",
    "              normalized by `n_items`\n",
    "              \n",
    "        3) hs_match : how many words product name of inquiry and HS commodity description share,\n",
    "              normalized by `n_comm`\n",
    "              \n",
    "        4) n_items : number of items in the supplier's catalogue\n",
    "        \n",
    "        5) n_comm : number of unique commodities the supplier exports\n",
    "        \n",
    "        6) isexporter : whether the supplier has shipped to buyer's country in the last five years\n",
    "    \"\"\"\n",
    "    \n",
    "    code, product, spec = inq['PRODUCT_CATEGORY_OID'], inq['PRODUCT_NAME'], inq['SPECIFICATION']\n",
    "    ctry = fetch_country(inq['COMPANY_OID'])\n",
    "    supp = fetch_suppliers(code)  # return DataFrame of suppliers selling product specified by code\n",
    "    supp_ban = supp.index\n",
    "    supp_export = fetch_export(supp_ban, ctry)  # return DataFrame indexed by `BAN_REAL`\n",
    "    supp = pd.concat([supp, supp_export], axis=1)\n",
    "    \n",
    "    # ========================================================\n",
    "    # Transform `supp` to features using `product`, and `spec`\n",
    "    # ========================================================\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def estimate_feature_dist(inqs):\n",
    "    \"\"\"Estimate and save population mean and standard deviation for each feature.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    inqs : DataFrame\n",
    "        Each row represents an inquiry.\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_map = map(compute_features, [row for lab, row in inqs.iterrows()])\n",
    "    stacked = reduce(lambda x, y: x.append(y), feature_map)\n",
    "    mean, std = stacked.mean(), stacked.std()\n",
    "    dist = pd.concat([mean, std], axis=1)\n",
    "    dist.columns = ['mean', 'std']\n",
    "    dist.to_csv('feature_distribution.csv')\n",
    "    return\n",
    "\n",
    "\n",
    "def normalize_features(X):\n",
    "    \"\"\"Return normalized features.\"\"\"\n",
    "    return (X - mean) / std\n",
    "\n",
    "\n",
    "def sigmoid(a):\n",
    "    \"\"\"Sigmoid function of an array.\"\"\"\n",
    "    return 1 / (1 + np.exp(-a))\n",
    "\n",
    "\n",
    "def predict_prob(X, theta):\n",
    "    \"\"\"Compute predicted probabilities.\"\"\"\n",
    "    return sigmoid(np.matmul(X, theta))\n",
    "\n",
    "\n",
    "# Some useful values\n",
    "n = 7\n",
    "alpha = 0.01\n",
    "dist = pd.read_csv('feature_distribution.csv', index_col=0)\n",
    "mean, std = dist['mean'], dist['std']\n",
    "\n",
    "# For each incoming inquiry Series `inq`, run:\n",
    "# ================================================================\n",
    "# Load current theta or initialize if not exists\n",
    "if len(glob('theta.txt')):\n",
    "    with open('theta.txt', 'r') as f:\n",
    "        theta = np.array([float(x) for x in f.read().split('\\n')])\n",
    "else:\n",
    "    theta = np.zeros(n)\n",
    "\n",
    "# Get data ready\n",
    "X = compute_features(inq)\n",
    "X = normalize_features(X)\n",
    "X['intercept'] = 1\n",
    "\n",
    "# Predict probabilities\n",
    "X['prob'] = predict_prob(X, theta)\n",
    "\n",
    "# Get top 10 suppliers\n",
    "top10 = X.sort_values('prob', ascending=False).head(10)\n",
    "\n",
    "# Fetch user response\n",
    "\n",
    "# Update theta using 10 steps of gradient descent\n",
    "theta, J = gradient_descent(top10, y, theta, alpha)\n",
    "\n",
    "with open('theta.txt', 'w') as f:\n",
    "    f.write('\\n'.join([str(x) for x in theta]))\n",
    "# ================================================================"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
