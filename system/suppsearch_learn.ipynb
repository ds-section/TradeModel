{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from glob import glob\n",
    "import slreg as slr\n",
    "\n",
    "\n",
    "def fetch_country(COMPANY_OID):\n",
    "    \"\"\"Return country of location of buyer's company.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def fetch_suppliers(code):\n",
    "    \"\"\"Return DataFrame of suppliers from TT selling product specified by code, indexed by `BAN_REAL`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    code : str\n",
    "        TAITRA code of len 4.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    suppliers : DataFrame\n",
    "        Columns: `n_items`, `item_name`, `item_desc`, 'upload_date', and 'update_date'.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def fetch_export(supp_ban, ctry):\n",
    "    \"\"\"Return DataFrame of export records for all suppliers contained in `supp_ban`,\n",
    "    indexed by `BAN_REAL`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    supp_ban : list-like\n",
    "        `BAN_REAL` of target suppliers.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    export : DataFrame\n",
    "        Columns: `n_comm` (number of unique commodities exported by the supplier), `hs_desc`\n",
    "        (HS descriptions of commodities exported), and `isexporter` (boolean, whether the supplier\n",
    "        has shipped to buyer's country in the last five years).\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def compute_features(inq):\n",
    "    \"\"\"Return DataFrame of calculated features.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    inq : Series\n",
    "        Buyer inquiry.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : DataFrame\n",
    "        At present there are fourteen features:\n",
    "        \n",
    "        1) n_items : number of items in the supplier's catalogue.\n",
    "        \n",
    "        2) name_comp : number of words shared by product name of inquiry and catalogue items,\n",
    "               normalized by `n_items`. measure of 'total compatibility'.\n",
    "              \n",
    "        3) name_max_comp : max number of shared words found in any single catalogue item. measure of\n",
    "               'maximal compatibility'.\n",
    "        \n",
    "        4) name_min_comp : min number of shared words found in any single catalogue item. measure of\n",
    "               'minimal compatibility'.\n",
    "        \n",
    "        5) desc_comp : analogous to `name_comp`, except taken between product specification of\n",
    "               inquiry and catalogue items. normalized by `n_items`.\n",
    "               \n",
    "        6) desc_max_comp : analogous to `name_max_comp`.\n",
    "        \n",
    "        7) desc_min_comp : analogous to `name_min_comp`.\n",
    "        \n",
    "        8) upload_rec : upload recency, equals to\n",
    "               max(0, `CREATION_DATE` from inquiry - 'upload_date' from suppliers).\n",
    "        \n",
    "        9) update_rec : update recency, equals to\n",
    "               max(0, `CREATION_DATE` from inquiry - 'update_date' from suppliers).\n",
    "        \n",
    "        10) n_comm : number of unique commodities the supplier exports.\n",
    "              \n",
    "        11) hs_comp : analogous to `name_comp`, except taken between product name of inquiry and HS\n",
    "                commodity description. normalized by `n_comm`.\n",
    "            \n",
    "        12) hs_max_comp : analogous to `name_max_comp`.\n",
    "        \n",
    "        13) hs_min_comp : analogous to `name_min_comp`.\n",
    "        \n",
    "        14) isexporter : whether the supplier has shipped to buyer's country in the last five years.\n",
    "    \"\"\"\n",
    "    \n",
    "    code, product, spec = inq['PRODUCT_CATEGORY_OID'], inq['PRODUCT_NAME'], inq['SPECIFICATION']\n",
    "    ctry = fetch_country(inq['COMPANY_OID'])\n",
    "    supp = fetch_suppliers(code)  # return DataFrame of suppliers selling product specified by code\n",
    "    supp_ban = supp.index\n",
    "    supp_export = fetch_export(supp_ban, ctry)  # return DataFrame indexed by `BAN_REAL`\n",
    "    supp = pd.concat([supp, supp_export], axis=1)\n",
    "    \n",
    "    # ========================================================\n",
    "    # Transform `supp` to features using `product`, and `spec`\n",
    "    # ========================================================\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def estimate_feature_dist(inqs):\n",
    "    \"\"\"Estimate and save population mean and standard deviation for each feature.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    inqs : DataFrame\n",
    "        Each row represents an inquiry.\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_map = map(compute_features, [row for lab, row in inqs.iterrows()])\n",
    "    stacked = reduce(lambda x, y: x.append(y), feature_map)\n",
    "    mean, std = stacked.mean(), stacked.std()\n",
    "    dist = pd.concat([mean, std], axis=1)\n",
    "    dist.columns = ['mean', 'std']\n",
    "    dist.to_csv('feature_distribution.csv')\n",
    "    return\n",
    "\n",
    "\n",
    "def normalize_features(X):\n",
    "    \"\"\"Return normalized features.\"\"\"\n",
    "    return (X - mean) / std\n",
    "\n",
    "\n",
    "# Some useful values\n",
    "n = 14\n",
    "alpha = 0.01\n",
    "dist = pd.read_csv('feature_distribution.csv', index_col=0)\n",
    "mean, std = dist['mean'], dist['std']\n",
    "\n",
    "# For each incoming inquiry Series `inq`, run:\n",
    "# ================================================================\n",
    "# Load current theta or initialize if not exists\n",
    "if len(glob('theta.txt')):\n",
    "    with open('theta.txt', 'r') as f:\n",
    "        theta = np.array([float(x) for x in f.read().split('\\n')])\n",
    "else:\n",
    "    theta = np.zeros(n + 1)\n",
    "\n",
    "# Get data ready\n",
    "X = compute_features(inq)\n",
    "X = normalize_features(X)\n",
    "X['intercept'] = 1\n",
    "\n",
    "# Predict probabilities\n",
    "X['prob'] = slr.predict_prob(X, theta)\n",
    "\n",
    "# Get top 10 suppliers\n",
    "top10 = X.sort_values('prob', ascending=False).drop('prob', axis=1).head(10)\n",
    "\n",
    "# Fetch user response Series `y`\n",
    "\n",
    "# Save y together with `inq` (broadcasted) and 10 `BAN_REAL`s\n",
    "\n",
    "# Update theta using 10 steps of gradient descent\n",
    "for i in range(10):\n",
    "    x = top10.iloc[i].values.reshape((1, n))\n",
    "    theta, J = slr.gradient_descent(x, y[[i]], theta, alpha)\n",
    "\n",
    "with open('theta.txt', 'w') as f:\n",
    "    f.write('\\n'.join([str(x) for x in theta]))\n",
    "# ================================================================"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
